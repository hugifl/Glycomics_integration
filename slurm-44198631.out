2024-01-14 12:29:18.150612: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-14 12:29:18.672270: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux2.6-glibc2.3-x86_64/lib:/cluster/apps/gcc-4.8.5/r-4.1.3-zhohf2ta256vpv74j4uq24doqdfqyllj/rlib/R/lib:/cluster/apps/gcc-4.8.5/zlib-1.2.9-dfllxkobdix3ujpfjwsnnyv6vj7ufwcw/lib:/cluster/apps/gcc-4.8.5/openblas-0.2.20-ut6yhgxs5opzdjsqbfm7kaodfpqj7haf/lib:/cluster/apps/nss/python/3.7.4/x86_64/lib64:/cluster/apps/gcc-4.8.5/hdf5-1.10.9-j3urjulfpkxdslamrubc4p4ssfv5g5iu/lib:/cluster/apps/gcc-4.8.5/fastqc-0.11.9-idl77akhjkw5ounkpxxur2vg74aigeep/lib:/cluster/apps/gcc-4.8.5/emboss-6.6.0-j6uwtc5qzuwmm37w4fetov5n4wabfskd/lib:/cluster/apps/gcc-4.8.5/boost-1.74.0-pyomvleapuufbg4siz7g3jwtkkvwfudc/lib:/cluster/apps/gcc-4.8.5/perl-5.34.0-75yvrlt7bfvt76rc7r2oh245oic3idvg/lib:/cluster/home/hugifl/resources/software/lib:/cluster/apps/lsf/10.1/linux2.6-glibc2.3-x86_64/lib::
2024-01-14 12:29:18.672320: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-01-14 12:29:22.655439: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux2.6-glibc2.3-x86_64/lib:/cluster/apps/gcc-4.8.5/r-4.1.3-zhohf2ta256vpv74j4uq24doqdfqyllj/rlib/R/lib:/cluster/apps/gcc-4.8.5/zlib-1.2.9-dfllxkobdix3ujpfjwsnnyv6vj7ufwcw/lib:/cluster/apps/gcc-4.8.5/openblas-0.2.20-ut6yhgxs5opzdjsqbfm7kaodfpqj7haf/lib:/cluster/apps/nss/python/3.7.4/x86_64/lib64:/cluster/apps/gcc-4.8.5/hdf5-1.10.9-j3urjulfpkxdslamrubc4p4ssfv5g5iu/lib:/cluster/apps/gcc-4.8.5/fastqc-0.11.9-idl77akhjkw5ounkpxxur2vg74aigeep/lib:/cluster/apps/gcc-4.8.5/emboss-6.6.0-j6uwtc5qzuwmm37w4fetov5n4wabfskd/lib:/cluster/apps/gcc-4.8.5/boost-1.74.0-pyomvleapuufbg4siz7g3jwtkkvwfudc/lib:/cluster/apps/gcc-4.8.5/perl-5.34.0-75yvrlt7bfvt76rc7r2oh245oic3idvg/lib:/cluster/home/hugifl/resources/software/lib:/cluster/apps/lsf/10.1/linux2.6-glibc2.3-x86_64/lib::
2024-01-14 12:29:22.657415: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux2.6-glibc2.3-x86_64/lib:/cluster/apps/gcc-4.8.5/r-4.1.3-zhohf2ta256vpv74j4uq24doqdfqyllj/rlib/R/lib:/cluster/apps/gcc-4.8.5/zlib-1.2.9-dfllxkobdix3ujpfjwsnnyv6vj7ufwcw/lib:/cluster/apps/gcc-4.8.5/openblas-0.2.20-ut6yhgxs5opzdjsqbfm7kaodfpqj7haf/lib:/cluster/apps/nss/python/3.7.4/x86_64/lib64:/cluster/apps/gcc-4.8.5/hdf5-1.10.9-j3urjulfpkxdslamrubc4p4ssfv5g5iu/lib:/cluster/apps/gcc-4.8.5/fastqc-0.11.9-idl77akhjkw5ounkpxxur2vg74aigeep/lib:/cluster/apps/gcc-4.8.5/emboss-6.6.0-j6uwtc5qzuwmm37w4fetov5n4wabfskd/lib:/cluster/apps/gcc-4.8.5/boost-1.74.0-pyomvleapuufbg4siz7g3jwtkkvwfudc/lib:/cluster/apps/gcc-4.8.5/perl-5.34.0-75yvrlt7bfvt76rc7r2oh245oic3idvg/lib:/cluster/home/hugifl/resources/software/lib:/cluster/apps/lsf/10.1/linux2.6-glibc2.3-x86_64/lib::
2024-01-14 12:29:22.657435: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2024-01-14 12:29:31.040006: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2024-01-14 12:29:31.040292: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (eu-g5-042-4): /proc/driver/nvidia/version does not exist
2024-01-14 12:29:31.044241: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
/cluster/apps/nss/python/3.7.4/x86_64/lib64/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.
  import pandas.util.testing as tm
/cluster/home/hugifl/.local/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  FutureWarning,
/cluster/home/hugifl/.local/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  FutureWarning,
Loaded checkpoint
Loaded from cache /cluster/scratch/hugifl/glycomics_only_markers_one_iter/1_init_lectin_codes.h5ad
Loaded from cache /cluster/scratch/hugifl/glycomics_only_markers_one_iter/1_init/evals.h5ad
Loaded checkpoint
Loaded checkpoint
Cache loading failed
Caching to /cluster/scratch/hugifl/glycomics_only_markers_one_iter/2_integration_iteration_1_lectin/evals.h5ad
Cache loading failed
Traceback (most recent call last):
  File "/cluster/home/hugifl/scim/utils_training.py", line 141, in visualize_latent_space
    evald = anndata.read(cache)
  File "/cluster/home/hugifl/.local/lib/python3.7/site-packages/anndata/_io/h5ad.py", line 224, in read_h5ad
    with h5py.File(filename, "r") as f:
  File "/cluster/home/hugifl/.local/lib/python3.7/site-packages/h5py/_hl/files.py", line 567, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)
  File "/cluster/home/hugifl/.local/lib/python3.7/site-packages/h5py/_hl/files.py", line 231, in make_fid
    fid = h5f.open(name, flags, fapl=fapl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 106, in h5py.h5f.open
FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/cluster/scratch/hugifl/glycomics_only_markers_one_iter/2_integration_iteration_1_AB/evals.h5ad', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "glycomics_iterative.py", line 73, in <module>
    main()
  File "glycomics_iterative.py", line 65, in main
    visualize_latent_space(trainer, full, source_technology, OUTDIR, LABEL, iteration=iteration)
  File "/cluster/home/hugifl/scim/utils_training.py", line 149, in visualize_latent_space
    codes.write(cache)
  File "/cluster/home/hugifl/.local/lib/python3.7/site-packages/anndata/_core/anndata.py", line 1924, in write_h5ad
    as_dense=as_dense,
  File "/cluster/home/hugifl/.local/lib/python3.7/site-packages/anndata/_io/h5ad.py", line 75, in write_h5ad
    with h5py.File(filepath, mode) as f:
  File "/cluster/home/hugifl/.local/lib/python3.7/site-packages/h5py/_hl/files.py", line 567, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)
  File "/cluster/home/hugifl/.local/lib/python3.7/site-packages/h5py/_hl/files.py", line 237, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 126, in h5py.h5f.create
FileNotFoundError: [Errno 2] Unable to create file (unable to open file: name = '/cluster/scratch/hugifl/glycomics_only_markers_one_iter/2_integration_iteration_1_AB/evals.h5ad', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)
